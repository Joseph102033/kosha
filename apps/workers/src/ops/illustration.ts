/**
 * OPS Illustration Generator using Cloudflare Workers AI
 * Generates safety incident illustrations using AI image generation
 */

import type { OPSInput } from './models';
import type { Env } from '../index';
import { callGemini } from '../ai/gemini';

/**
 * Translate Korean incident cause to English for AI understanding
 */
function translateIncidentCause(cause: string): string {
  // Simple translation hints for common Korean terms
  const translations: Record<string, string> = {
    'ì•ˆì „ë²¨íŠ¸': 'safety harness',
    'ì•ˆì „ëª¨': 'hard hat / safety helmet',
    'ì¶”ë½': 'falling from height',
    'ë¹„ê³„': 'scaffolding',
    'ì‚¬ë‹¤ë¦¬': 'ladder',
    'í™”í•™ë¬¼ì§ˆ': 'chemical substance',
    'ëˆ„ì¶œ': 'leak / spill',
    'í™”ì¬': 'fire',
    'í­ë°œ': 'explosion',
    'ì¥ë¹„': 'equipment',
    'ê³ ì¥': 'malfunction / failure',
    'ì‘ì—…ì': 'worker',
    'í˜„ì¥': 'work site / construction site',
    'ê±´ì„¤': 'construction',
    'ê³µì¥': 'factory / facility',
    'ë¯¸ì°©ìš©': 'not wearing / without',
    'ë¶€ì¡±': 'insufficient / lack of',
    'ë¶ˆëŸ‰': 'defective / faulty',
    'ë¶€ì‹¤': 'inadequate / poor',
  };

  let translated = cause;
  for (const [korean, english] of Object.entries(translations)) {
    translated = translated.replace(new RegExp(korean, 'g'), english);
  }

  return translated;
}

/**
 * Generate scene description using Gemini AI
 * Analyzes incident details and creates detailed visual scene description
 */
async function generateSceneDescriptionWithAI(input: OPSInput, env: Env): Promise<string | null> {
  const prompt = `ë‹¹ì‹ ì€ ì‚°ì—…ì•ˆì „ ê¸°ìˆ  ì‚½í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¬í•´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ìƒì„¸í•œ ì¥ë©´ ë¬˜ì‚¬ë¥¼ ì˜ë¬¸ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

**ì¬í•´ ì •ë³´:**
- ì¬í•´ ìœ í˜•: ${input.incidentType}
- ë°œìƒ ì¥ì†Œ: ${input.location}
- ì¬í•´ ê°œìš”: ${input.incidentCause}
${input.agentObject ? `- ê°€í•´ë¬¼: ${input.agentObject}` : ''}
${input.hazardObject ? `- ìœ„í—˜ë¬¼: ${input.hazardObject}` : ''}

**ìš”êµ¬ì‚¬í•­:**

1. **ì •í™•í•œ ì¥ë©´ ë¬˜ì‚¬**: ì¬í•´ ê°œìš”ì˜ ë‚´ìš©ì„ ì •í™•íˆ ë°˜ì˜í•œ êµ¬ì²´ì ì¸ ì¥ë©´
   - ì‘ì—…ìì˜ ìœ„ì¹˜, ìì„¸, í–‰ë™
   - ìœ„í—˜ ìš”ì†Œì˜ êµ¬ì²´ì ì¸ ìƒíƒœ
   - ì•ˆì „ ì¥ë¹„ ì°©ìš©/ë¯¸ì°©ìš© ìƒíƒœ
   - í™˜ê²½ ìš”ì†Œ (ë†’ì´, êµ¬ì¡°ë¬¼, ì£¼ë³€ í™˜ê²½)

2. **ì‹œê°ì  ë””í…Œì¼**: ì´ë¯¸ì§€ ìƒì„±ì— í•„ìš”í•œ êµ¬ì²´ì ì¸ ì‹œê° ì •ë³´
   - ì‹œì  (isometric 3/4 view)
   - ìƒ‰ìƒ (OSHA ì•ˆì „ìƒ‰: yellow #FFCC00, orange #FF6600, red #CC0000)
   - ì¡°ëª… (studio lighting with shadows)
   - ìŠ¤íƒ€ì¼ (professional technical diagram, CAD-style)

3. **ì˜ë¬¸ìœ¼ë¡œ ì‘ì„±**: ì´ë¯¸ì§€ ìƒì„± AIê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì˜ë¬¸ìœ¼ë¡œ ì‘ì„±

4. **ê°„ê²°í•¨**: 500ì ì´ë‚´ë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ

**ì¶œë ¥ í˜•ì‹ (Plain Text, ì˜ë¬¸):**
Professional technical safety illustration depicting [incident scenario].

Scene details:
- Worker: [position, posture, action, safety equipment status]
- Hazard: [specific hazard element and its state]
- Environment: [location context, structures, height]
- Key elements: [specific details that must be visible]

Visual style: Isometric 3/4 view, CAD-style rendering, OSHA safety colors, studio lighting.

**ì¤‘ìš”**: ì¬í•´ ê°œìš”(${input.incidentCause})ì˜ ë‚´ìš©ì„ ì •í™•íˆ ë°˜ì˜í•˜ì„¸ìš”.`;

  const response = await callGemini(prompt, env, {
    temperature: 0.7,
    maxOutputTokens: 1024,
  });

  return response;
}

/**
 * Compact KOSHA Style Guide for AI image generation
 * Optimized for appropriate emotional tone in fatal accident documentation
 *
 * CRITICAL: Facial expressions must convey serious/distressed tone
 * - These are fatal workplace accidents for government safety reports
 * - Workers must show alarm/distress, NEVER smiling or happy
 * - Reference: Official KOSHA safety manual illustrations
 */
const KOSHA_STYLE_COMPACT = `KOSHA safety manual: cartoon with 2px black outlines, flat colors. Yellow helmet, blue/gray work clothes, red danger zones, white cloud effects. Light gray background. NO text, NO gradients. CRITICAL: Worker's face shows DISTRESS - furrowed worried eyebrows, mouth open in alarm, eyes wide in shock. NOT smiling, NOT happy. Panicked body language (arms flailing, falling). Serious safety incident, emergency situation. Yellow star burst at impact point.`.trim();

/**
 * Generate detailed English prompt for AI image generation
 * Uses AI-generated scene description with KOSHA style guide
 */
async function generateImagePrompt(input: OPSInput, env: Env): Promise<string> {
  // Simplified approach: use compact style + incident details
  // Skip Gemini for illustration prompt (causes MAX_TOKENS issues)
  return generateImagePromptFallback(input);
}

/**
 * Fallback: Template-based prompt generation
 */
function generateImagePromptFallback(input: OPSInput): string {
  const typeMap: Record<string, string> = {
    'fall': 'fall from height incident',
    'ì¶”ë½': 'fall from height incident',
    'chemical spill': 'chemical spill / hazmat incident',
    'í™”í•™ë¬¼ì§ˆ ëˆ„ì¶œ': 'chemical spill / hazmat incident',
    'fire': 'fire emergency',
    'í™”ì¬': 'fire emergency',
    'explosion': 'explosion incident',
    'í­ë°œ': 'explosion incident',
    'equipment failure': 'equipment failure incident',
    'ì¥ë¹„ ê³ ì¥': 'equipment failure incident',
    'other': 'workplace safety incident',
    'ê¸°íƒ€': 'workplace safety incident',
  };

  const normalizedType = input.incidentType.toLowerCase().trim();
  const incidentTypeDesc = typeMap[normalizedType] || 'workplace safety incident';

  // Translate incident cause for better AI understanding
  const translatedCause = translateIncidentCause(input.incidentCause || '');

  // Extract location context
  const locationContext = input.location?.includes('ê±´ì„¤') || input.location?.includes('í˜„ì¥')
    ? 'construction site'
    : input.location?.includes('ê³µì¥') || input.location?.includes('ì‹œì„¤')
    ? 'industrial facility'
    : 'workplace';

  // Build compact prompt under 2048 chars
  let prompt = `${KOSHA_STYLE_COMPACT} ${incidentTypeDesc} at ${locationContext}. Worker in yellow helmet, ${locationContext === 'construction site' ? 'blue' : 'gray'} clothes, showing ALARM on face (worried eyebrows, open mouth). Scene: ${translatedCause}.`;

  // Add type-specific details with emphasis on distress
  if (normalizedType.includes('fall') || normalizedType.includes('ì¶”ë½')) {
    prompt += ' Fall: worker mid-air with panicked expression, arms flailing outward, mouth open in shock, dotted motion arc, scaffolding/ladder collapsing.';
  } else if (normalizedType.includes('chemical') || normalizedType.includes('í™”í•™')) {
    prompt += ' Chemical emergency: worker with distressed worried face, vapor/fume lines rising, protective gear insufficient, hazard container leaking.';
  } else if (normalizedType.includes('fire') || normalizedType.includes('í™”ì¬')) {
    prompt += ' Fire emergency: worker showing alarm, flames/smoke, urgent evacuation posture.';
  } else {
    prompt += ' Worker in distress, concerned facial expression, emergency situation.';
  }

  prompt += ' Yellow star at impact, white clouds showing force, red danger area. Serious tone, NOT happy. NO text.';

  // Ensure under 2048 chars
  if (prompt.length > 2040) {
    console.warn(`âš ï¸ Prompt truncated from ${prompt.length} to 2040 chars`);
    prompt = prompt.substring(0, 2040);
  }

  console.log('ğŸ“ Illustration prompt generated:', {
    length: prompt.length,
    preview: prompt.substring(0, 200) + '...',
  });

  return prompt;
}

/**
 * Generate illustration using Cloudflare Workers AI
 * Returns base64-encoded image or null if generation fails
 */
export async function generateIllustration(
  input: OPSInput,
  env: Env
): Promise<string | null> {
  try {
    const prompt = await generateImagePrompt(input, env);

    // Use Cloudflare Workers AI to generate image
    // Model: @cf/black-forest-labs/flux-1-schnell (fast, high quality)
    const response = await env.AI.run(
      '@cf/black-forest-labs/flux-1-schnell',
      {
        prompt: prompt,
        num_steps: 8, // Maximum steps for best quality (takes longer but more accurate)
      }
    );

    // Handle different response types
    // Workers AI can return ReadableStream, ArrayBuffer, or object with image property
    if (response instanceof ReadableStream) {
      const reader = response.getReader();
      const chunks: Uint8Array[] = [];

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        chunks.push(value);
      }

      // Combine chunks
      const totalLength = chunks.reduce((acc, chunk) => acc + chunk.length, 0);
      const combined = new Uint8Array(totalLength);
      let offset = 0;
      for (const chunk of chunks) {
        combined.set(chunk, offset);
        offset += chunk.length;
      }

      // Convert to base64
      const base64 = btoa(String.fromCharCode(...combined));
      return `data:image/png;base64,${base64}`;
    } else if (response instanceof ArrayBuffer) {
      const bytes = new Uint8Array(response);
      const base64 = btoa(String.fromCharCode(...bytes));
      return `data:image/png;base64,${base64}`;
    } else if (typeof response === 'object' && response !== null) {
      // Check if response has image data
      const anyResponse = response as any;
      if (anyResponse.image && anyResponse.image instanceof ArrayBuffer) {
        const bytes = new Uint8Array(anyResponse.image);
        const base64 = btoa(String.fromCharCode(...bytes));
        return `data:image/png;base64,${base64}`;
      } else if (typeof anyResponse.image === 'string') {
        // Already base64 or data URL
        if (anyResponse.image.startsWith('data:')) {
          return anyResponse.image;
        } else {
          return `data:image/png;base64,${anyResponse.image}`;
        }
      } else if (anyResponse.data && anyResponse.data instanceof ArrayBuffer) {
        const bytes = new Uint8Array(anyResponse.data);
        const base64 = btoa(String.fromCharCode(...bytes));
        return `data:image/png;base64,${base64}`;
      }
    }

    return null;
  } catch (error) {
    console.error('Illustration generation error:', error);
    return null;
  }
}
